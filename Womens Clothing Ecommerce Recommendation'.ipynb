{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Womens Clothing Ecommerce Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Women E-Commerce Clothing Reviews dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset includes 23486 rows and 10 feature variables. Each row corresponds to a customer review, and includes the variables:\n",
    "\n",
    "**Objective**\n",
    "The objective is to classify whether the customer recommends the product or not\n",
    "\n",
    "**Columns**\n",
    "1. Clothing ID: Integer Categorical variable that refers to the specific piece being reviewed.\n",
    "\n",
    "2. Age: Positive Integer variable of the reviewers age.\n",
    "    \n",
    "3. Title: String variable for the title of the review.\n",
    "    \n",
    "4. Review Text: String variable for the review body.\n",
    "    \n",
    "5. Rating: Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\n",
    "    \n",
    "6. Recommended IND: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended.\n",
    "    \n",
    "7. Positive Feedback Count: Positive Integer documenting the number of other customers who found this review positive.\n",
    "8. Division Name: Categorical name of the product high level division.\n",
    "    \n",
    "9. Department Name: Categorical name of the product department name.\n",
    "    \n",
    "10. Class Name: Categorical name of the product class name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing the packages and the dataset(unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re,string\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First unlabeled data is being taken for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset(unlabeled)\n",
    "eccom_unlabel = pd.read_csv('eccomerce_unlabeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                      NaN   \n",
       "1           1         1080   34                      NaN   \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5   \n",
       "2  I had such high hopes for this dress and reall...       3   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5   \n",
       "4  This shirt is very flattering to all due to th...       5   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the head of the dataset\n",
    "eccom_unlabel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Unnamed:0\n",
    "eccom_unlabel = eccom_unlabel.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Checking for null values and treating them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clothing ID                   0\n",
       "Age                           0\n",
       "Title                      3810\n",
       "Review Text                 845\n",
       "Rating                        0\n",
       "Positive Feedback Count       0\n",
       "Division Name                14\n",
       "Department Name              14\n",
       "Class Name                   14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "eccom_unlabel.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the null values with 0\n",
    "eccom_unlabel = eccom_unlabel.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "def clean_string(string):                                                         # The entire document is cleaned defining clean_string\n",
    "  try:\n",
    "    string=re.sub(r'^https?:\\/\\/<>.*[\\r\\n]*','',string,flags=re.MULTILINE)\n",
    "    string=re.sub(r\"[^A-Za-z0-9]\",\" \",string)\n",
    "    words=string.strip().lower().split()\n",
    "    return \" \".join(words)\n",
    "  except:\n",
    "    return \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the Review Text column\n",
    "eccom_unlabel['Review Text']=eccom_unlabel['Review Text'].apply(clean_string)                                  # Finally cleaned format is applied on the reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of samples \n",
      ": 23486\n"
     ]
    }
   ],
   "source": [
    "# Getting the no of samples\n",
    "print (\"No.of samples \\n:\",(len(eccom_unlabel)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Splitting each review for getting word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting each review to have word tokens\n",
    "Document=[]\n",
    "for doc in eccom_unlabel['Review Text']:\n",
    "  Document.append(doc.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23486"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of the document\n",
    "len(Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'dress', 'is', 'perfection', 'so', 'pretty', 'and', 'flattering']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the split reviews\n",
    "Document[11]                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "['bought', 'the', 'black', 'xs', 'to', 'go', 'under', 'the', 'larkspur', 'midi', 'dress', 'because', 'they', 'didn', 't', 'bother', 'lining', 'the', 'skirt', 'portion', 'grrrrrrrrrrr', 'my', 'stats', 'are', '34a', '28', '29', '36', 'and', 'the', 'xs', 'fit', 'very', 'smoothly', 'around', 'the', 'chest', 'and', 'was', 'flowy', 'around', 'my', 'lower', 'half', 'so', 'i', 'would', 'say', 'it', 's', 'running', 'big', 'the', 'straps', 'are', 'very', 'pretty', 'and', 'it', 'could', 'easily', 'be', 'nightwear', 'too', 'i', 'm', '5', '6', 'and', 'it', 'came', 'to', 'just', 'below', 'my', 'knees']\n"
     ]
    }
   ],
   "source": [
    "print(len(Document[13]))                                                          # Lenth of the 10th document ,  It has 524 words in it\n",
    "print(Document[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Applying the Word 2 Vector in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import logging\n",
    "import logging                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 02:38:30,536 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2020-06-10 02:38:30,537 : INFO : collecting all words and their counts\n",
      "2020-06-10 02:38:30,537 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-06-10 02:38:30,624 : INFO : PROGRESS: at sentence #10000, processed 591576 words, keeping 9788 word types\n",
      "2020-06-10 02:38:30,706 : INFO : PROGRESS: at sentence #20000, processed 1192608 words, keeping 13252 word types\n",
      "2020-06-10 02:38:30,737 : INFO : collected 14168 word types from a corpus of 1399859 raw words and 23486 sentences\n",
      "2020-06-10 02:38:30,738 : INFO : Loading a fresh vocabulary\n",
      "2020-06-10 02:38:30,755 : INFO : effective_min_count=10 retains 3505 unique words (24% of original 14168, drops 10663)\n",
      "2020-06-10 02:38:30,756 : INFO : effective_min_count=10 leaves 1375465 word corpus (98% of original 1399859, drops 24394)\n",
      "2020-06-10 02:38:30,768 : INFO : deleting the raw counts dictionary of 14168 items\n",
      "2020-06-10 02:38:30,768 : INFO : sample=0.001 downsamples 60 most-common words\n",
      "2020-06-10 02:38:30,769 : INFO : downsampling leaves estimated 927149 word corpus (67.4% of prior 1375465)\n",
      "2020-06-10 02:38:30,778 : INFO : estimated required memory for 3505 words and 50 dimensions: 3154500 bytes\n",
      "2020-06-10 02:38:30,779 : INFO : resetting layer weights\n",
      "2020-06-10 02:38:30,817 : INFO : training model with 4 workers on 3505 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-10 02:38:31,320 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-10 02:38:31,320 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-10 02:38:31,326 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-10 02:38:31,329 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-10 02:38:31,330 : INFO : EPOCH - 1 : training on 1399859 raw words (926716 effective words) took 0.5s, 1820398 effective words/s\n",
      "2020-06-10 02:38:31,848 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-10 02:38:31,856 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-10 02:38:31,857 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-10 02:38:31,859 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-10 02:38:31,860 : INFO : EPOCH - 2 : training on 1399859 raw words (926707 effective words) took 0.5s, 1764013 effective words/s\n",
      "2020-06-10 02:38:32,366 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-10 02:38:32,374 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-10 02:38:32,377 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-10 02:38:32,379 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-10 02:38:32,380 : INFO : EPOCH - 3 : training on 1399859 raw words (927244 effective words) took 0.5s, 1794960 effective words/s\n",
      "2020-06-10 02:38:32,936 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-10 02:38:32,936 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-10 02:38:32,936 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-10 02:38:32,945 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-10 02:38:32,946 : INFO : EPOCH - 4 : training on 1399859 raw words (926547 effective words) took 0.5s, 1721398 effective words/s\n",
      "2020-06-10 02:38:33,461 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-10 02:38:33,461 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-10 02:38:33,466 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-10 02:38:33,469 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-10 02:38:33,469 : INFO : EPOCH - 5 : training on 1399859 raw words (927750 effective words) took 0.5s, 1783689 effective words/s\n",
      "2020-06-10 02:38:33,470 : INFO : training on a 6999295 raw words (4634964 effective words) took 2.7s, 1747431 effective words/s\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "# Training the Word 2 Vec model\n",
    "model=gensim.models.Word2Vec(Document,                                           # List of reviews\n",
    "                          min_count=10,                                          # we want words appearing atleast 10 times in the vocab otherwise ignore \n",
    "                          workers=4,                                             # Use these many worker threads to train the model (=faster training with multicore machines\n",
    "                           size=50,                                              # it means aword is represented by 50 numbers,in other words the number of neorons in hidden layer is 50 \n",
    "                          window=5)                                              # 5 neighbors on the either side of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3505\n"
     ]
    }
   ],
   "source": [
    "# Vocab words length\n",
    "print(len(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# Dimension of each vector\n",
    "print(model.wv.vector_size)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3505, 50)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the vectors\n",
    "model.wv.vectors.shape  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Finding similarities with the given words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 02:38:36,183 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('band', 0.8767274618148804),\n",
       " ('waistband', 0.8104285001754761),\n",
       " ('string', 0.7814128994941711),\n",
       " ('gaping', 0.7778440713882446),\n",
       " ('drawstring', 0.7710692882537842),\n",
       " ('adjustable', 0.769332230091095),\n",
       " ('pleats', 0.7525403499603271),\n",
       " ('seam', 0.7354264259338379),\n",
       " ('empire', 0.7313741445541382),\n",
       " ('slight', 0.7260311841964722)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding for similarity with the given word\n",
    "model.wv.most_similar(\"elastic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thick', 0.8345667123794556),\n",
       " ('sheer', 0.8288353681564331),\n",
       " ('heavy', 0.809961199760437),\n",
       " ('itchy', 0.8096404671669006),\n",
       " ('stiff', 0.7992092967033386),\n",
       " ('scratchy', 0.7959129810333252),\n",
       " ('flimsy', 0.786957859992981),\n",
       " ('substantial', 0.7443051338195801),\n",
       " ('stretchy', 0.7316536903381348),\n",
       " ('clingy', 0.7047092318534851)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding for similarity with the given word\n",
    "model.wv.most_similar(\"thin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dressy', 0.8592880964279175),\n",
       " ('professional', 0.7696312069892883),\n",
       " ('formal', 0.760412871837616),\n",
       " ('everyday', 0.7477831840515137),\n",
       " ('office', 0.7186474800109863),\n",
       " ('business', 0.7093658447265625),\n",
       " ('versatile', 0.707597017288208),\n",
       " ('statement', 0.691520094871521),\n",
       " ('night', 0.687825620174408),\n",
       " ('fancy', 0.6745193004608154)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding for similarity with the given word\n",
    "model.wv.most_similar(\"casual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Getting the vectors for the given words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.176295  , -0.45844513, -2.5261326 , -0.80591667, -1.2087256 ,\n",
       "        1.1122762 , -0.37928355, -0.37312347,  1.0273516 , -1.8836976 ,\n",
       "        0.64909995, -3.514252  , -0.5397141 ,  0.7332397 ,  1.2798525 ,\n",
       "        0.8106409 ,  0.18375742,  0.14993669, -2.5257838 , -0.8134738 ,\n",
       "        1.8921258 , -0.911001  ,  1.6516182 ,  0.84880006,  0.7936893 ,\n",
       "        0.77655774,  2.263096  , -0.08433716,  0.4509756 , -1.7902579 ,\n",
       "       -0.3375684 , -0.91015935, -1.4423649 ,  2.4932146 ,  1.0489174 ,\n",
       "       -0.28217334, -2.4501994 , -0.7577879 , -0.09641537, -1.5083404 ,\n",
       "       -0.24535249,  0.99679506, -2.2660577 ,  0.6605534 ,  0.0208884 ,\n",
       "       -2.7304204 , -0.88867676, -0.21991247, -2.7705712 ,  2.6571522 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the vectors for the given word\n",
    "model.wv[\"good\"]                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07112465,  0.2635235 , -0.2920789 , -0.15770221,  0.15314275,\n",
       "       -0.13191661,  0.01873192, -0.09989369,  0.22969107,  0.07122152,\n",
       "       -0.09486619, -0.0740578 ,  0.09546576,  0.10995583,  0.0222888 ,\n",
       "        0.0044242 , -0.07734506,  0.00986315,  0.01937341, -0.0689163 ,\n",
       "       -0.172906  , -0.16759486,  0.08832748,  0.00245991,  0.03076484,\n",
       "       -0.07046505, -0.12630461, -0.09965779,  0.21890326,  0.02806855,\n",
       "       -0.07381344,  0.09758095, -0.13874969,  0.08826001, -0.13341103,\n",
       "        0.20776902,  0.16249816, -0.19754645, -0.0517891 ,  0.00286017,\n",
       "       -0.11863533, -0.2139306 ,  0.15927167, -0.3561667 , -0.16951601,\n",
       "       -0.01266793,  0.15520552,  0.18639816, -0.02249255,  0.02963131],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the vectors for the given word\n",
    "model.wv['ugly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 02:38:40,334 : INFO : saving Word2Vec object under word 2 vector woman ecommerce, separately None\n",
      "2020-06-10 02:38:40,335 : INFO : not storing attribute vectors_norm\n",
      "2020-06-10 02:38:40,336 : INFO : not storing attribute cum_table\n",
      "2020-06-10 02:38:40,355 : INFO : saved word 2 vector woman ecommerce\n"
     ]
    }
   ],
   "source": [
    "# Saving the model\n",
    "model.save(\"word 2 vector woman ecommerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pre-trained Word2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Reading the labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "eccom_label = pd.read_csv('eccommerce_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>absolutely wonderful silky and sexy and comfor...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>love this dress it s sooo pretty i happened to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>i had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>i love love love this jumpsuit it s fun flirty...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>this shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                        0   \n",
       "1           1         1080   34                        0   \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  absolutely wonderful silky and sexy and comfor...       4                1   \n",
       "1  love this dress it s sooo pretty i happened to...       5                1   \n",
       "2  i had such high hopes for this dress and reall...       3                0   \n",
       "3  i love love love this jumpsuit it s fun flirty...       5                1   \n",
       "4  this shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eccom_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the unwanted column\n",
    "eccom_label = eccom_label.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Splitting x and y variables into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test using train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(eccom_label['Review Text'],eccom_label['Recommended IND'],test_size=0.3,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Building the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building tokenizer\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#Vocab size\n",
    "top_words = 10000\n",
    "\n",
    "t = Tokenizer(num_words=top_words)\n",
    "t.fit_on_texts(X_train.tolist())\n",
    "\n",
    "#Get the word index for each of the word in the review\n",
    "X_train = t.texts_to_sequences(X_train.tolist())\n",
    "X_test = t.texts_to_sequences(X_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Using pad sequences to make each review size equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pad sequences to make each review size equal\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "\n",
    "#Each review size\n",
    "max_review_length = 300\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length,padding='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Building Embedding Matrix from Pre-Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 02:44:25,292 : INFO : loading Word2Vec object from word 2 vector woman ecommerce\n",
      "2020-06-10 02:44:25,542 : INFO : loading wv recursively from word 2 vector woman ecommerce.wv.* with mmap=None\n",
      "2020-06-10 02:44:25,542 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-06-10 02:44:25,542 : INFO : loading vocabulary recursively from word 2 vector woman ecommerce.vocabulary.* with mmap=None\n",
      "2020-06-10 02:44:25,546 : INFO : loading trainables recursively from word 2 vector woman ecommerce.trainables.* with mmap=None\n",
      "2020-06-10 02:44:25,546 : INFO : setting ignored attribute cum_table to None\n",
      "2020-06-10 02:44:25,547 : INFO : loaded word 2 vector woman ecommerce\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded word2vec model..\n",
      "Model shape:  (3505, 50)\n"
     ]
    }
   ],
   "source": [
    "# Building Embedding Matrix from Pre-Trained model\n",
    "word2vec = gensim.models.Word2Vec.load('word 2 vector woman ecommerce')\n",
    "\n",
    "#Embedding Length\n",
    "embedding_vector_length = word2vec.wv.vectors.shape[1]\n",
    "\n",
    "print('Loaded word2vec model..')\n",
    "print('Model shape: ', word2vec.wv.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector size\n",
    "word2vec.wv.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Building matrix for the current data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize embedding matrix to all zeros\n",
    "embedding_matrix = np.zeros((top_words + 1, # Vocablury size + 1,, we add 1 to vocab size for padding\n",
    "                             embedding_vector_length))\n",
    "\n",
    "#Steps for populating embedding matrix\n",
    "\n",
    "#1. Check each word in tokenizer vocablury to see if it exist in pre-trained\n",
    "# word2vec model.\n",
    "#2. If found, update embedding matrix with embeddings for the word \n",
    "# from word2vec model\n",
    "\n",
    "for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n",
    "    if i > top_words:\n",
    "        break\n",
    "    if word in word2vec.wv.vocab:\n",
    "        embedding_vector = word2vec.wv[word]\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.17629504, -0.45844513, -2.52613258, -0.80591667, -1.20872557,\n",
       "        1.1122762 , -0.37928355, -0.37312347,  1.02735162, -1.88369763,\n",
       "        0.64909995, -3.51425195, -0.5397141 ,  0.73323971,  1.27985251,\n",
       "        0.81064087,  0.18375742,  0.14993669, -2.52578378, -0.81347382,\n",
       "        1.89212584, -0.91100103,  1.65161824,  0.84880006,  0.79368931,\n",
       "        0.77655774,  2.26309609, -0.08433716,  0.4509756 , -1.79025793,\n",
       "       -0.3375684 , -0.91015935, -1.44236493,  2.49321461,  1.04891741,\n",
       "       -0.28217334, -2.45019937, -0.75778788, -0.09641537, -1.50834036,\n",
       "       -0.24535249,  0.99679506, -2.26605773,  0.6605534 ,  0.0208884 ,\n",
       "       -2.73042035, -0.88867676, -0.21991247, -2.77057123,  2.65715218])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking embeddings for word 'good'\n",
    "embedding_matrix[t.word_index['good']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Building the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the graph\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Dense, Embedding, Flatten\n",
    "\n",
    "#Build a sequential model\n",
    "model1 = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. Adding the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 02:46:18,085 : WARNING : From C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Adding the embedding layer\n",
    "model1.add(Embedding(top_words + 1,\n",
    "                    embedding_vector_length,\n",
    "                    input_length=max_review_length,\n",
    "                    weights=[embedding_matrix],                                    # Pre-trained embedding\n",
    "                    trainable=False)                                               # We do not want to change embedding\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. Flattening embedding and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 02:46:45,247 : WARNING : From C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "2020-06-10 02:46:45,397 : WARNING : From C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#Flatten embedding layer output and flatten layers\n",
    "model1.add(Flatten())                                                             # Flatten enables us to bring down the dimension of the prepared data\n",
    "model1.add(Dense(200,activation='relu'))                                          # Dense layer is for fully connected layer\n",
    "model1.add(Dense(100,activation='relu'))\n",
    "model1.add(Dropout(0.5))                                                          # Dropout is required to avoid overfiting & make the model generalize\n",
    "model1.add(Dense(60,activation='relu'))\n",
    "model1.add(Dropout(0.4))\n",
    "model1.add(Dense(30,activation='relu'))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(1,activation='sigmoid'))                                         # We've used sigmoid because output variable is binary\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18. Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16440 samples, validate on 7046 samples\n",
      "Epoch 1/5\n",
      "16440/16440 [==============================] - 4s 247us/sample - loss: 0.4335 - acc: 0.8172 - val_loss: 0.3783 - val_acc: 0.8280\n",
      "Epoch 2/5\n",
      "16440/16440 [==============================] - 3s 209us/sample - loss: 0.3370 - acc: 0.8467 - val_loss: 0.3615 - val_acc: 0.8406\n",
      "Epoch 3/5\n",
      "16440/16440 [==============================] - 4s 258us/sample - loss: 0.2525 - acc: 0.8888 - val_loss: 0.4093 - val_acc: 0.8430\n",
      "Epoch 4/5\n",
      "16440/16440 [==============================] - 4s 264us/sample - loss: 0.1560 - acc: 0.9380 - val_loss: 0.5198 - val_acc: 0.8419\n",
      "Epoch 5/5\n",
      "16440/16440 [==============================] - 4s 272us/sample - loss: 0.0936 - acc: 0.9685 - val_loss: 0.7392 - val_acc: 0.8415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b9f3955780>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executing the graph\n",
    "model1.fit(X_train,Y_train,\n",
    "          epochs=5,\n",
    "          batch_size=200,          \n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19. Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99993086],\n",
       "       [0.94569564],\n",
       "       [0.9877014 ],\n",
       "       [0.9994308 ]], dtype=float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing\n",
    "model1.predict(X_test[5:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>i love tracy reese dresses but this one is not...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>i aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>Shimmer, surprisingly goes with lots</td>\n",
       "      <td>i ordered this in carbon for store pick up and...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1077</td>\n",
       "      <td>24</td>\n",
       "      <td>Flattering</td>\n",
       "      <td>i love this dress i usually get an xs but it r...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                                 Title  \\\n",
       "5         1080   49               Not for the very petite   \n",
       "6          858   39                  Cagrcoal shimmer fun   \n",
       "7          858   39  Shimmer, surprisingly goes with lots   \n",
       "8         1077   24                            Flattering   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "5  i love tracy reese dresses but this one is not...       2                0   \n",
       "6  i aded this in my basket at hte last mintue to...       5                1   \n",
       "7  i ordered this in carbon for store pick up and...       4                1   \n",
       "8  i love this dress i usually get an xs but it r...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "5                        4         General         Dresses    Dresses  \n",
       "6                        1  General Petite            Tops      Knits  \n",
       "7                        4  General Petite            Tops      Knits  \n",
       "8                        0         General         Dresses    Dresses  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eccom_label.iloc[5:9,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
