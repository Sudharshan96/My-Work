{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Projects\n",
    "# Mercedes Safety time prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "1. [Dataset Description](#mercedes)\n",
    "2. [Importing the packages and dataset](#packages)\n",
    "3. [Exploring the dataset](#explore)\n",
    "4. [Checking for null values](#null)\n",
    "5. [Feature Engineering](#fe)    \n",
    "6. [Scaling](#s)\n",
    "7. [PCA](#p)\n",
    "     - 7.1 [Fitting a default model](#fp)\n",
    "     - 7.2 [Finding optimum components using variance score,plot and scree plot](#op)\n",
    "     - 7.3 [Fitting the PCA model to dataset](#fop)\n",
    "8. [Splitting the dataset](#split)\n",
    "9. [Linear Regression](#lr)\n",
    "     - 9.1 [Fitting the Linear Regression model](#flr)\n",
    "     - 9.2 [Evaluating the Linear Regression model](#elr)\n",
    "10. [Decision Tree](#dt)\n",
    "     - 10.1 [Fitting the Decision Tree Model](#fdt)\n",
    "     - 10.2 [Evaluating the Decision Tree Model](#edt)\n",
    "     - 10.3 [Parameter Tuning for Decision Tree](#ptdt)\n",
    "     - 10.4 [Fitting the Decision Tree model after parameter tuning](#ptfdt)\n",
    "     - 10.5 [Evaluating the Decision Tree after parameter tuning](#ptedt)    \n",
    "11. [Random Forest](#rf)\n",
    "     - 11.1 [Fitting the Random Forest Model](#frf)\n",
    "     - 11.2 [Evaluating the Random Forest Model](#erf)\n",
    "     - 11.3 [Parameter Tuning for Random Forest](#ptrf)\n",
    "     - 11.4 [Fitting the Random Forest after parameter tuning](#ptfrf)\n",
    "     - 11.5 [Evaluating the Random Forest after parameter tuning](#pterf)\n",
    "12. [Support Vector Machine](#svm)\n",
    "     - 12.1 [Fitting the Support Vector Machine Model](#fsvm)\n",
    "     - 12.2 [Evaluating the Support Vector Machine Model](#esvm)\n",
    "     - 12.3 [Parameter Tuning for Support Vector Machine](#ptsvm)\n",
    "     - 12.4 [Fitting the Support Vector Machine model after parameter tuning](#ptfsvm)\n",
    "     - 12.5 [Evaluating the Support Vector Machine after parameter tuning](#ptesvm)\n",
    "13. [K Nearest Neighbors](#knn)\n",
    "     - 13.1 [Fitting the K Nearest Neighbors Model](#fknn)\n",
    "     - 13.2 [Evaluating the K Nearest Neighbors Model](#eknn)\n",
    "     - 13.3 [Parameter Tuning for K Nearest Neighbors](#ptknn)\n",
    "     - 13.4 [Fitting the K Nearest Neighbors model after parameter tuning](#ptfknn)\n",
    "     - 13.5 [Evaluating the K Nearest Neighbors after parameter tuning](#pteknn)\n",
    "14. [XG Boost Classifier](#xgb)\n",
    "     - 14.1 [Fitting the XG Boost Classifier Model](#fxgb)\n",
    "     - 14.2 [Evaluating theXG Boost Classifier Model](#exgb)\n",
    "     - 14.3 [Parameter Tuning for XG Boost Classifier](#ptxgb)\n",
    "     - 14.4 [Fitting the XG Boost Classifier model after parameter tuning](#ptfxgb)\n",
    "     - 14.5 [Evaluating the XG Boost Classifier after parameter tuning](#ptexgb)\n",
    "15. [Ada Boost Classifier](#ada)\n",
    "     - 15.1 [Fitting the Ada Boost Classifier Model](#fada)\n",
    "     - 15.2 [Evaluating the Ada Boost Classifier Model](#eada)\n",
    "     - 15.3 [Parameter Tuning for Ada Boost Classifier](#ptada)\n",
    "     - 15.4 [Fitting the Ada Boost Classifier model after parameter tuning](#ptfada)\n",
    "     - 15.5 [Evaluating the Ada Boost Classifier after parameter tuning](#pteada)\n",
    "16. [Gradient Boost Classifier](#gradient)\n",
    "     - 16.1 [Fitting the Gradient Boost Classifier Model](#fgradient)\n",
    "     - 16.2 [Evaluating the Gradient Boost Classifier Model](#egradient)\n",
    "     - 16.3 [Parameter Tuning for Gradient Boost Classifier](#ptgradient)\n",
    "     - 16.4 [Fitting the Gradient Boost Classifier model after parameter tuning](#ptfgradient)\n",
    "     - 16.5 [Evaluating the Gradient Boost Classifier after parameter tuning](#ptegradient)\n",
    "17. [Bagging Classifier](#bag)\n",
    "     - 17.1 [Fitting the Bagging Classifier Model](#fbag)\n",
    "     - 17.2 [Evaluating the Bagging Classifier Model](#ebag)\n",
    "     - 17.3 [Parameter Tuning for Bagging Classifier](#ptbag)\n",
    "     - 17.4 [Fitting the Bagging Classifier model after parameter tuning](#ptfbag)\n",
    "     - 17.5 [Evaluating the Bagging Classifier after parameter tuning](#ptebag)\n",
    "18. [Comparison table of all metrics](#ct)\n",
    "8. [Appendix](#appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mercedes-Benz Greener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dataset Description  <a id='mercedes'>\n",
    "**Objective**\n",
    "The objective is to predict the y column which is the time taken for testing for each car.\n",
    "    \n",
    "**Descriptions**\n",
    "This dataset contains an anonymized set of variables (X0 to X385), each representing a custom feature in a Mercedes car.\n",
    "\n",
    "** Note: This is confidential data and we will not be able to provide description for each of the anonymized set of variables.\n",
    "\n",
    "For example, a variable could be 4WD, added air suspension, or a head-up display.\n",
    "\n",
    "The ground truth is labeled ‘y’ and represents the time (in seconds) that the car took to pass testing for each variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Importing the packages and dataset  <a id='packages'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "mercedes = pd.read_csv('mercedes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploring the dataset  <a id='explore'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the head of the dataset\n",
    "mercedes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 378)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the dataset\n",
    "mercedes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA is to be performed for finding out the most optimum features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.0</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "      <td>4209.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4205.960798</td>\n",
       "      <td>100.669318</td>\n",
       "      <td>0.013305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075077</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.428130</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318841</td>\n",
       "      <td>0.057258</td>\n",
       "      <td>0.314802</td>\n",
       "      <td>0.020670</td>\n",
       "      <td>0.009503</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.001426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2437.608688</td>\n",
       "      <td>12.679381</td>\n",
       "      <td>0.114590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263547</td>\n",
       "      <td>0.233716</td>\n",
       "      <td>0.494867</td>\n",
       "      <td>0.021796</td>\n",
       "      <td>0.051061</td>\n",
       "      <td>0.086872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466082</td>\n",
       "      <td>0.232363</td>\n",
       "      <td>0.464492</td>\n",
       "      <td>0.142294</td>\n",
       "      <td>0.097033</td>\n",
       "      <td>0.089524</td>\n",
       "      <td>0.086872</td>\n",
       "      <td>0.040752</td>\n",
       "      <td>0.021796</td>\n",
       "      <td>0.037734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2095.000000</td>\n",
       "      <td>90.820000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4220.000000</td>\n",
       "      <td>99.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6314.000000</td>\n",
       "      <td>109.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8417.000000</td>\n",
       "      <td>265.320000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID            y          X10     X11          X12  \\\n",
       "count  4209.000000  4209.000000  4209.000000  4209.0  4209.000000   \n",
       "mean   4205.960798   100.669318     0.013305     0.0     0.075077   \n",
       "std    2437.608688    12.679381     0.114590     0.0     0.263547   \n",
       "min       0.000000    72.110000     0.000000     0.0     0.000000   \n",
       "25%    2095.000000    90.820000     0.000000     0.0     0.000000   \n",
       "50%    4220.000000    99.150000     0.000000     0.0     0.000000   \n",
       "75%    6314.000000   109.010000     0.000000     0.0     0.000000   \n",
       "max    8417.000000   265.320000     1.000000     0.0     1.000000   \n",
       "\n",
       "               X13          X14          X15          X16          X17  ...  \\\n",
       "count  4209.000000  4209.000000  4209.000000  4209.000000  4209.000000  ...   \n",
       "mean      0.057971     0.428130     0.000475     0.002613     0.007603  ...   \n",
       "std       0.233716     0.494867     0.021796     0.051061     0.086872  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     1.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "              X375         X376         X377         X378         X379  \\\n",
       "count  4209.000000  4209.000000  4209.000000  4209.000000  4209.000000   \n",
       "mean      0.318841     0.057258     0.314802     0.020670     0.009503   \n",
       "std       0.466082     0.232363     0.464492     0.142294     0.097033   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              X380         X382         X383         X384         X385  \n",
       "count  4209.000000  4209.000000  4209.000000  4209.000000  4209.000000  \n",
       "mean      0.008078     0.007603     0.001663     0.000475     0.001426  \n",
       "std       0.089524     0.086872     0.040752     0.021796     0.037734  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 370 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of mercedes\n",
    "mercedes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We need to scale before going for the PCA analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Checking for null values  <a id='null'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID      0\n",
       "y       0\n",
       "X0      0\n",
       "X1      0\n",
       "X2      0\n",
       "X3      0\n",
       "X4      0\n",
       "X5      0\n",
       "X6      0\n",
       "X8      0\n",
       "X10     0\n",
       "X11     0\n",
       "X12     0\n",
       "X13     0\n",
       "X14     0\n",
       "X15     0\n",
       "X16     0\n",
       "X17     0\n",
       "X18     0\n",
       "X19     0\n",
       "X20     0\n",
       "X21     0\n",
       "X22     0\n",
       "X23     0\n",
       "X24     0\n",
       "X26     0\n",
       "X27     0\n",
       "X28     0\n",
       "X29     0\n",
       "X30     0\n",
       "       ..\n",
       "X355    0\n",
       "X356    0\n",
       "X357    0\n",
       "X358    0\n",
       "X359    0\n",
       "X360    0\n",
       "X361    0\n",
       "X362    0\n",
       "X363    0\n",
       "X364    0\n",
       "X365    0\n",
       "X366    0\n",
       "X367    0\n",
       "X368    0\n",
       "X369    0\n",
       "X370    0\n",
       "X371    0\n",
       "X372    0\n",
       "X373    0\n",
       "X374    0\n",
       "X375    0\n",
       "X376    0\n",
       "X377    0\n",
       "X378    0\n",
       "X379    0\n",
       "X380    0\n",
       "X382    0\n",
       "X383    0\n",
       "X384    0\n",
       "X385    0\n",
       "Length: 378, dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "mercedes.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We could see there are no null values present**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature Engineering  <a id='fe'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before applying PCA to label the data so to import Label Encoder and encode all the values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encoding all the categorical columns\n",
    "mercedes['X0'] = le.fit_transform(mercedes['X0'])\n",
    "mercedes['X1'] = le.fit_transform(mercedes['X1'])\n",
    "mercedes['X2'] = le.fit_transform(mercedes['X2'])\n",
    "mercedes['X3'] = le.fit_transform(mercedes['X3'])\n",
    "mercedes['X4'] = le.fit_transform(mercedes['X4'])\n",
    "mercedes['X5'] = le.fit_transform(mercedes['X5'])\n",
    "mercedes['X6'] = le.fit_transform(mercedes['X6'])\n",
    "mercedes['X8'] = le.fit_transform(mercedes['X8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'y', 'X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8',\n",
       "       ...\n",
       "       'X375', 'X376', 'X377', 'X378', 'X379', 'X380', 'X382', 'X383', 'X384',\n",
       "       'X385'],\n",
       "      dtype='object', length=378)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mercedes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "mercedes = mercedes.drop('ID',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Scaling <a id='s'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning x and y values\n",
    "x = mercedes.drop('y',1)\n",
    "y = mercedes['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 376)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "x_scaled = ss.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = pd.DataFrame(x_scaled,columns=x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. PCA <a id='p'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Fitting a default PCA <a id='fp'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=376, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing PCA and fitting it to the dataset\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(376)\n",
    "pca.fit(x_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Finding optimum components using variance score,plot and scree plot <a id='op'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916975486878112"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting variance score for 200\n",
    "pca.explained_variance_ratio_[:200].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variance plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(200,0.9,'200')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variance plot\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.annotate('200',xy=(200, .90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scree plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scree plot to find the features with min variance\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Explained variance\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As its become stable at  250 so we can take  250 components from the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Fitting the PCA model to dataset <a id='fop'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA to the dataset\n",
    "pca = PCA(n_components=200)\n",
    "X_scaled = pca.fit_transform(x_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Splitting the dataset <a id='split'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing train test split and splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X_scaled,y,test_size=0.25,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Linear Regression <a id='lr'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Fitting the Linear Regression model <a id = 'flr'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the LinearRegression and training and testing the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "lin_pred = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Evaluating the Linear Regression model <a id = 'elr'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the metrics\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.46149399671013"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE score for Linear Regression\n",
    "lr_rmse = np.sqrt(metrics.mean_squared_error(lin_pred,y_test))\n",
    "lr_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.  Decision Tree  <a id = 'dt'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1  Fitting the Decision Tree model  <a id = 'fdt'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Decision Tree and fitting the model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(x_train,y_train)\n",
    "dt_pred = dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Evaluating the Decision Tree model <a id = 'edt'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.081013004360317"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE for Decision Tree\n",
    "dt_rmse = np.sqrt(metrics.mean_squared_error(dt_pred,y_test))\n",
    "dt_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Parameter Tuning <a id = 'ptdt'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=DecisionTreeRegressor(criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features=None,\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   presort=False,\n",
       "                                                   random_state=None,\n",
       "                                                   splitter='best'),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'criterion': ['mse'],\n",
       "                                        'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing  Randomizedsearchcv and finding out optimal parameters for Decision Tree\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "params = {'max_depth': np.arange(1,20),'criterion':['mse']}\n",
    "dr = DecisionTreeRegressor()\n",
    "tree = RandomizedSearchCV(dr, params, cv=3 , return_train_score = True) # RandomizedSearchCV\n",
    "tree.fit(x_scaled,y)# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'criterion': 'mse'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal parameters\n",
    "tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 Fitting the Decision Tree model after parameter Tuning <a id = 'ptfdt'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model and training and testing after parameter tuning\n",
    "dtr = DecisionTreeRegressor(criterion='mse',max_depth=5)\n",
    "dtr.fit(x_train,y_train)\n",
    "pred1 = dtr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5 Evaluating the Decision Tree model after parameter Tuning <a id = 'ptfdt'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.4104160040942"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_tune_rmse = np.sqrt(metrics.mean_squared_error(pred1,y_test))\n",
    "dt_tune_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Random Forest <a id = 'rf'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Fitting the Random Forest model <a id = 'frf'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing Random Forest Classifier and fitting the model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(x_train,y_train)\n",
    "rf_pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Evaluating the Random Forest model <a id = 'erf'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.511756629243507"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rmse = np.sqrt(metrics.mean_squared_error(rf_pred,y_test))\n",
    "rf_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 Parameter Tuning <a id = 'ptrf'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators='warn',\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_state=None, verbose=0,\n",
       "                                                   warm_start=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'criterion': ['mse'],\n",
       "                                        'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Finding optimal parameters for Random Forest using Randomized Search CV\n",
    "rf = RandomForestRegressor()\n",
    "params1 = {'n_estimators': np.arange(1,20),'criterion':['mse']}\n",
    "forest = RandomizedSearchCV(rf, params, cv=3 , return_train_score = True) # GridSearchCV\n",
    "forest.fit(x_scaled,y)# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'criterion': 'mse'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal parameters\n",
    "forest.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4 Fitting the Random Forest model after parameter Tuning <a id = 'ptfrf'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest after parameter tuning\n",
    "rfr = RandomForestRegressor(criterion='mse',max_depth=4)\n",
    "rfr.fit(x_train,y_train)\n",
    "pred2 = rfr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5 Evaluating the Random Forest model after parameter Tuning <a id = 'pterf'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.016400263917298"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_tune_rmse = np.sqrt(metrics.mean_squared_error(pred2,y_test))\n",
    "rf_tune_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Support Vector Machine <a id = 'svm'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  12.1 Fitting the Support Vector Machine model  <a id = 'fsvm'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing Support Vector\n",
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "svr.fit(x_train,y_train)\n",
    "svr_pred = svr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Evaluating the Support Vector model <a id = 'esvm'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.764399256364"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rmse = np.sqrt(metrics.mean_squared_error(svr_pred,y_test))\n",
    "svr_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3  Parameter Tuning <a id = 'ptsvm'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                                 epsilon=0.1, gamma='auto_deprecated',\n",
       "                                 kernel='rbf', max_iter=-1, shrinking=True,\n",
       "                                 tol=0.001, verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'C': [0.01, 0.1, 1],\n",
       "                                        'gamma': [0.01, 0.1, 1],\n",
       "                                        'kernel': ['linear', 'rbf']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Randomized Search cv to find the optimal parameters for SVM\n",
    "params2 = {'kernel':['linear','rbf'],'C': [0.01, 0.1,1],'gamma': [0.01,0.1,1]}\n",
    "svr = SVR()\n",
    "support = RandomizedSearchCV(svr, params2, cv=5 , return_train_score = True) # RandomizedSearchCV\n",
    "support.fit(x_scaled,y)# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'linear', 'gamma': 1, 'C': 0.01}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal parameters\n",
    "support.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.4 Fitting the Support Vector Machine model after parameter Tuning <a id = 'ptfsvm'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model and training and testing\n",
    "svrr = SVR(C = 1,gamma = 0.01,kernel = 'linear')\n",
    "svrr.fit(x_train,y_train)\n",
    "pred3 = svrr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.5 Evaluating the Support Vector Machine model after parameter Tuning <a id = 'ptesvm'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.31979764991908"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_tune_rmse = np.sqrt(metrics.mean_squared_error(pred3,y_test))\n",
    "svr_tune_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. K Nearest Neighbors <a id = 'knn'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 Fitting the K Nearest Neighbors model <a id = 'fknn'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing KNearest Neighbors and fitting the model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(x_train,y_train)\n",
    "knn_pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 Evaluating the K Nearest Neighbors model <a id = 'eknn'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.69966252122418"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_rmse = np.sqrt(metrics.mean_squared_error(knn_pred,y_test))\n",
    "knn_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3 Parameter Tuning <a id = 'ptknn'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
       "                                                 metric='minkowski',\n",
       "                                                 metric_params=None,\n",
       "                                                 n_jobs=None, n_neighbors=5,\n",
       "                                                 p=2, weights='uniform'),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'leaf_size': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       "                                        'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       "                                        'p': [1, 2]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding optimal parameters\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]\n",
    "params4 = {'leaf_size':np.arange(1,50),'n_neighbors':np.arange(1,30),'p':[1,2]}\n",
    "knn = KNeighborsRegressor()\n",
    "neighbor = RandomizedSearchCV(knn, params4, cv=3 , return_train_score = True) # RandomizedSearchCV\n",
    "neighbor.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': 1, 'n_neighbors': 15, 'leaf_size': 20}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal parameters\n",
    "neighbor.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.4 Fitting the Support Vector Machine model after parameter Tuning <a id = 'ptfknn'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model and training and testing after parameter tuning\n",
    "knnr = KNeighborsRegressor(n_neighbors=15,p=1,leaf_size=20)\n",
    "knnr.fit(x_train,y_train)\n",
    "pred4 = knnr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.5 Evaluating the Support Vector Machine model after parameter Tuning <a id = 'pteknn'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.776853352981329"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE score for KNN after parameter tuning\n",
    "knn_tune_rmse = np.sqrt(metrics.mean_squared_error(pred4,y_test))\n",
    "knn_tune_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. XG Boost Classifier <a id = 'xgb'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing XGB Regressor and fitting the model\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(max_depth=3,learning_rate=0.1,n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1 Fitting the XG Boost Classifier model <a id = 'fxgb'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:25] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Training and testing the model\n",
    "xgb_model.fit(x_train, y_train)\n",
    "xgb_pred = xgb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2 Evaluating the XG Boost Classifier <a id = 'exgb'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.811011662886562"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE for XGB model\n",
    "xgb_rmse = np.sqrt(metrics.mean_squared_error(xgb_pred,y_test))\n",
    "xgb_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3 Parameter Tuning <a id = 'ptxgb'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:17] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:19] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:23] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:24] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:26] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:28] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:30] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:32] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:41] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:42] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:44] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:48] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:50] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:52] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:55] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:56] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:58] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:59] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:02] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:05] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:07] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:08] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:09] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:10] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:10] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:11] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:13] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:16] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:18] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:20] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:20] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:22] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:23] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:24] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          importance_type='gain',\n",
       "                                          learning_rate=0.1, max_delta_step=0,\n",
       "                                          max_depth=3, min_child_weight=1,\n",
       "                                          missing=None, n_estimators=100,\n",
       "                                          n_jobs=1, nthread=None,\n",
       "                                          objective='reg:linear',\n",
       "                                          random_state=0, reg_alpha=0,\n",
       "                                          reg_lambda=1, scale_pos_weight=1,\n",
       "                                          seed=None, silent=None, subsample=1,\n",
       "                                          verbosity=1),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.05],\n",
       "                                        'max_depth': [10, 15, 20, 30],\n",
       "                                        'n_estimators': range(5, 20, 2)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding optimal parameters using Randomized Search CV\n",
    "param_grid1 = {\"max_depth\": [10,15,20,30],\n",
    "              \"n_estimators\": range(5,20,2) ,  \n",
    "              \"learning_rate\": [0.01,0.05]}\n",
    " \n",
    "\n",
    "XGB = RandomizedSearchCV(xgb_model,param_distributions=param_grid1,\n",
    "                           cv = 5)\n",
    "XGB.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 19, 'max_depth': 10, 'learning_rate': 0.05}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal parameters\n",
    "XGB.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4 Fitting the XG Boost Classifier model after parameter Tuning <a id = 'ptfxgb'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model after parameter tuning\n",
    "xgbr = XGBRegressor(n_estimators=19,max_depth=10,learning_rate=0.05)\n",
    "xgbr.fit(x_train,y_train)\n",
    "xgbr_pred = xgbr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.5 Evaluating the XG Boost Classifier model after parameter Tuning <a id = 'ptexgb'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.98335536130937"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE score for XGB after parameter tuning\n",
    "xgb_tune_rmse = np.sqrt(metrics.mean_squared_error(xgbr_pred,y_test))\n",
    "xgb_tune_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Ada Boost Classifier <a id = 'ab'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.1 Fitting the Ada Boost Classifier model  <a id = 'fada'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Adaboost and fitting the model\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ab = AdaBoostRegressor()\n",
    "ab.fit(x_train,y_train)\n",
    "ab_pred = ab.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.2 Evaluating the Ada Boost Classifier model <a id = 'eada'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.83717181598334"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE score for Adaboost\n",
    "ab_rmse = np.sqrt(metrics.mean_squared_error(ab_pred,y_test))\n",
    "ab_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3 Parameter Tuning <a id = 'ptada'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=AdaBoostRegressor(base_estimator=None,\n",
       "                                               learning_rate=1.0, loss='linear',\n",
       "                                               n_estimators=50,\n",
       "                                               random_state=None),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.05, 0.1, 0.5,\n",
       "                                                          1],\n",
       "                                        'n_estimators': range(5, 20, 2)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding optimal parameters using Randomized Search CV\n",
    "param_grid1 = {\"n_estimators\": range(5,20,2) ,  \n",
    "              \"learning_rate\": [0.01,0.05,0.1,0.5,1]}\n",
    " \n",
    "\n",
    "AB = RandomizedSearchCV(ab,param_distributions=param_grid1,\n",
    "                           cv = 5)\n",
    "AB.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 11, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal parameters\n",
    "AB.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.4 Fitting the XG Boost Classifier model after parameter Tuning <a id = 'ptfada'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model after parameter tuning\n",
    "abr = AdaBoostRegressor(n_estimators=11,learning_rate=0.1)\n",
    "abr.fit(x_train,y_train)\n",
    "abr_pred = abr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.5 Evaluating the XG Boost Classifier model after parameter Tuning <a id = 'pteada'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.458488861260326"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE score for Adaboost after parameter tuning\n",
    "ab_tune_rmse = np.sqrt(metrics.mean_squared_error(abr_pred,y_test))\n",
    "ab_tune_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Gradient Boosting Classifier <a id = 'gradient'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.1 Fitting the Gradient Boost Classifier model <a id = 'fgradient'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing GradientBoosting and fitting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(x_train,y_train)\n",
    "gb_pred = gb.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.2 Evaluating the Gradient Boost Classifier model <a id = 'egradient'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.909953522606019"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE score for Gradient Boosting\n",
    "gb_rmse = np.sqrt(metrics.mean_squared_error(gb_pred,y_test))\n",
    "gb_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.3  Parameter Tuning <a id = 'ptgradient'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=GradientBoostingRegressor(alpha=0.9,\n",
       "                                                       criterion='friedman_mse',\n",
       "                                                       init=None,\n",
       "                                                       learning_rate=0.1,\n",
       "                                                       loss='ls', max_depth=3,\n",
       "                                                       max_features=None,\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_iter_no_change=None,\n",
       "                                                       presort='auto',\n",
       "                                                       random_state=None,\n",
       "                                                       subsample=1.0,\n",
       "                                                       tol=0.0001,\n",
       "                                                       validation_fraction=0.1,\n",
       "                                                       verbose=0,\n",
       "                                                       warm_start=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.05, 0.1, 0.5,\n",
       "                                                          1],\n",
       "                                        'n_estimators': range(5, 20, 2)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding optimal parameters using Randomized Search CV\n",
    "param_grid1 = {\"n_estimators\": range(5,20,2) ,  \n",
    "              \"learning_rate\": [0.01,0.05,0.1,0.5,1]}\n",
    " \n",
    "\n",
    "GB = RandomizedSearchCV(gb,param_distributions=param_grid1,\n",
    "                           cv = 5)\n",
    "GB.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 9, 'learning_rate': 0.5}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal parameters\n",
    "GB.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.4 Fitting the Gradient Boosting Classifier model after parameter Tuning <a id = 'ptfgradient'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model after parameter tuning\n",
    "gbr = GradientBoostingRegressor(n_estimators=9,learning_rate=0.5)\n",
    "gbr.fit(x_train,y_train)\n",
    "gbr_pred = gbr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.5 Evaluating the Gradient Boosting Classifier model after parameter Tuning <a id = 'ptegradient'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.520711980315454"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE score for Gradient Boosting after parameter tuning\n",
    "gb_tune_rmse = np.sqrt(metrics.mean_squared_error(gbr_pred,y_test))\n",
    "gb_tune_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Bagging Classifier <a id = 'bag'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.1 Fitting the Bagging Classifier model <a id = 'fbag'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Bagging Regressor and fitting the model\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "br = BaggingRegressor()\n",
    "br.fit(x_train,y_train)\n",
    "br_pred = br.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.2 Evaluating the Bagging Classifier model <a id = 'ebag'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.55534085948009"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE score for Bagging Regressor\n",
    "br_rmse = np.sqrt(metrics.mean_squared_error(br_pred,y_test))\n",
    "br_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.3 Parameter Tuning <a id = 'ptbag'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=BaggingRegressor(base_estimator=None,\n",
       "                                              bootstrap=True,\n",
       "                                              bootstrap_features=False,\n",
       "                                              max_features=1.0, max_samples=1.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'max_samples': [0.05, 0.1, 0.2, 0.5],\n",
       "                                        'n_estimators': range(5, 20, 2)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding optimal parameters for Bagging Regressor\n",
    "param_grid1 = {\"n_estimators\": range(5,20,2) ,  \n",
    "              \"max_samples\": [0.05, 0.1, 0.2, 0.5]}\n",
    " \n",
    "\n",
    "BR = RandomizedSearchCV(br,param_distributions=param_grid1,\n",
    "                           cv = 5)\n",
    "BR.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 15, 'max_samples': 0.1}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal parameters\n",
    "BR.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.4 Fitting the Bagging Classifier model after parameter Tuning <a id = 'ptfbag'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model after parameter tuning\n",
    "brr = BaggingRegressor(n_estimators=15,max_samples=0.1)\n",
    "brr.fit(x_train,y_train)\n",
    "brr_pred = brr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Comparison table of all metrics <a id = 'ct'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.970088196207008"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE score for Bagging Regressor after parameter tuning\n",
    "br_tune_rmse = np.sqrt(metrics.mean_squared_error(brr_pred,y_test))\n",
    "br_tune_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 17.5 Evaluating the Bagging Classifier model after parameter Tuning <a id = 'ptebag'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'Metrics': ['Before Parameter Tune RMSE','After Parameter Tune RMSE'],'Linear Regression':[lr_rmse,'NA'],\n",
    "           'Decision Tree Regressor':[dt_rmse,dt_tune_rmse],'Ramdom Forest Regressor':[rf_rmse,rf_tune_rmse],'Support Vector Regressor':[svr_rmse,svr_tune_rmse],\n",
    "          'KNearestNeighbor Regressor':[knn_rmse,knn_tune_rmse],\n",
    "          'XG Boost Regressor':[xgb_rmse,xgb_tune_rmse],\n",
    "          'Ada Boost Regressor':[ab_rmse,ab_tune_rmse],\n",
    "          'Gradient Boosting Regressor':[gb_rmse,gb_tune_rmse],\n",
    "          'Bagging Regressor':[br_rmse,br_tune_rmse]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>Decision Tree Regressor</th>\n",
       "      <th>Ramdom Forest Regressor</th>\n",
       "      <th>Support Vector Regressor</th>\n",
       "      <th>KNearestNeighbor Regressor</th>\n",
       "      <th>XG Boost Regressor</th>\n",
       "      <th>Ada Boost Regressor</th>\n",
       "      <th>Gradient Boosting Regressor</th>\n",
       "      <th>Bagging Regressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Before Parameter Tune RMSE</td>\n",
       "      <td>46.4615</td>\n",
       "      <td>13.081013</td>\n",
       "      <td>9.511757</td>\n",
       "      <td>9.764399</td>\n",
       "      <td>9.699663</td>\n",
       "      <td>8.811012</td>\n",
       "      <td>12.837172</td>\n",
       "      <td>8.909954</td>\n",
       "      <td>9.555341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After Parameter Tune RMSE</td>\n",
       "      <td>NA</td>\n",
       "      <td>10.410416</td>\n",
       "      <td>10.016400</td>\n",
       "      <td>9.319798</td>\n",
       "      <td>9.776853</td>\n",
       "      <td>38.983355</td>\n",
       "      <td>10.458489</td>\n",
       "      <td>9.520712</td>\n",
       "      <td>9.970088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Metrics Linear Regression  Decision Tree Regressor  \\\n",
       "0  Before Parameter Tune RMSE           46.4615                13.081013   \n",
       "1   After Parameter Tune RMSE                NA                10.410416   \n",
       "\n",
       "   Ramdom Forest Regressor  Support Vector Regressor  \\\n",
       "0                 9.511757                  9.764399   \n",
       "1                10.016400                  9.319798   \n",
       "\n",
       "   KNearestNeighbor Regressor  XG Boost Regressor  Ada Boost Regressor  \\\n",
       "0                    9.699663            8.811012            12.837172   \n",
       "1                    9.776853           38.983355            10.458489   \n",
       "\n",
       "   Gradient Boosting Regressor  Bagging Regressor  \n",
       "0                     8.909954           9.555341  \n",
       "1                     9.520712           9.970088  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Appendix <a id = 'appendix'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataframe we can see that Gradient Boosting is the best model followed by KNN and Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
